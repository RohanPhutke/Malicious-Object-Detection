{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is to detect malicious objects in the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- -----------\n",
      "asttokens           2.4.1\n",
      "certifi             2024.8.30\n",
      "charset-normalizer  3.4.0\n",
      "colorama            0.4.6\n",
      "comm                0.2.2\n",
      "contourpy           1.3.0\n",
      "cycler              0.12.1\n",
      "debugpy             1.8.9\n",
      "decorator           5.1.1\n",
      "exceptiongroup      1.2.2\n",
      "executing           2.1.0\n",
      "filelock            3.16.1\n",
      "fonttools           4.55.0\n",
      "fsspec              2024.10.0\n",
      "idna                3.10\n",
      "importlib_metadata  8.5.0\n",
      "importlib_resources 6.4.5\n",
      "ipykernel           6.29.5\n",
      "ipython             8.18.1\n",
      "jedi                0.19.2\n",
      "Jinja2              3.1.4\n",
      "jupyter_client      8.6.3\n",
      "jupyter_core        5.7.2\n",
      "kiwisolver          1.4.7\n",
      "MarkupSafe          3.0.2\n",
      "matplotlib          3.9.2\n",
      "matplotlib-inline   0.1.7\n",
      "mpmath              1.3.0\n",
      "nest-asyncio        1.6.0\n",
      "networkx            3.2.1\n",
      "numpy               2.0.2\n",
      "opencv-python       4.10.0.84\n",
      "packaging           24.2\n",
      "pandas              2.2.3\n",
      "parso               0.8.4\n",
      "pillow              11.0.0\n",
      "pip                 24.3.1\n",
      "platformdirs        4.3.6\n",
      "prompt_toolkit      3.0.48\n",
      "psutil              6.1.0\n",
      "pure_eval           0.2.3\n",
      "py-cpuinfo          9.0.0\n",
      "Pygments            2.18.0\n",
      "pyparsing           3.2.0\n",
      "python-dateutil     2.9.0.post0\n",
      "pytz                2024.2\n",
      "pywin32             308\n",
      "PyYAML              6.0.2\n",
      "pyzmq               26.2.0\n",
      "requests            2.32.3\n",
      "scipy               1.13.1\n",
      "seaborn             0.13.2\n",
      "setuptools          58.1.0\n",
      "six                 1.16.0\n",
      "stack-data          0.6.3\n",
      "sympy               1.13.1\n",
      "torch               2.5.1\n",
      "torchvision         0.20.1\n",
      "tornado             6.4.2\n",
      "tqdm                4.67.0\n",
      "traitlets           5.14.3\n",
      "typing_extensions   4.12.2\n",
      "tzdata              2024.2\n",
      "ultralytics         8.3.36\n",
      "ultralytics-thop    2.0.12\n",
      "urllib3             2.2.3\n",
      "wcwidth             0.2.13\n",
      "zipp                3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Specified value was saved.\n"
     ]
    }
   ],
   "source": [
    "!setx http_proxy \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\91800\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\91800\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.20.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020E46BF02B0>, 'Connection to 173.31.2.3 timed out. (connect timeout=15)')': /whl/cu118/torchaudio/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020E46BF03A0>, 'Connection to 173.31.2.3 timed out. (connect timeout=15)')': /whl/cu118/torchaudio/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020E46BF04F0>, 'Connection to 173.31.2.3 timed out. (connect timeout=15)')': /whl/cu118/torchaudio/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020E46BF06A0>, 'Connection to 173.31.2.3 timed out. (connect timeout=15)')': /whl/cu118/torchaudio/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020E46BF0760>, 'Connection to 173.31.2.3 timed out. (connect timeout=15)')': /whl/cu118/torchaudio/\n",
      "ERROR: Could not find a version that satisfies the requirement torchaudio (from versions: none)\n",
      "ERROR: No matching distribution found for torchaudio\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --proxy http://iit2022047:2002-04-15@173.31.2.3:8080\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\91800\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:493\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\91800\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\91800\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOLO images input, txt output\n",
    "# Yolo starting code\n",
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the modified YOLO model (make sure the path points to your customized model)\n",
    "model = YOLO(\"yolod_best.pt\")\n",
    "\n",
    "# Specify the image or folder containing images for prediction\n",
    "source = \"our_images\"  # Replace with your actual path\n",
    "\n",
    "# Run inference with specified options\n",
    "results = model.predict(\n",
    "    source=source,\n",
    "    save=True,        # Save annotated images or videos\n",
    "    save_txt=True,    # Save results in a text file format with [class] [x_center] [y_center] [width] [height] [confidence]\n",
    "    imgsz=640,        # Image size for inference (can be adjusted)\n",
    "    conf=0.5, \n",
    "    # show = True,    # Confidence threshold (can be adjusted based on your needs)\n",
    "    save_conf=True,   # Include confidence scores in the saved text files\n",
    "    device='cpu'   # Use GPU for faster inference (change to 'cpu' if GPU is not available)\n",
    ")\n",
    "\n",
    "# Identify the directory where labels are saved\n",
    "labels_dir = results[0].save_dir  # save_dir attribute provides the directory path\n",
    "\n",
    "# Construct the path variable for the label files\n",
    "labels_path = os.path.join(labels_dir, \"labels\")  # 'labels' is the folder containing the text files\n",
    "\n",
    "print(f\"Labels are saved in: {labels_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next We will create depth map of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DepthMap images input, depth map output\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Hardcoded values\n",
    "    img_path = 'our_images'  # Path to the images folder\n",
    "    outdir = 'depth_output'  # Output directory\n",
    "    encoder = 'vits'  # Encoder type ('vits', 'vitb', 'vitl', 'vitg')\n",
    "    input_size = 518  # Input size for images\n",
    "    pred_only = False  # Flag for prediction only\n",
    "    grayscale = False  # Flag for grayscale depth map\n",
    "\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "    # Encoder configurations\n",
    "    model_configs = {\n",
    "        'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "        'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "        'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "        'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "    }\n",
    "\n",
    "    # Initialize the depth model\n",
    "    depth_anything = DepthAnythingV2(**model_configs[encoder])\n",
    "    depth_anything.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "    depth_anything = depth_anything.to(DEVICE).eval()\n",
    "\n",
    "    # Get the filenames from img_path (if it's a directory or file)\n",
    "    if os.path.isfile(img_path):\n",
    "        if img_path.endswith('txt'):\n",
    "            with open(img_path, 'r') as f:\n",
    "                filenames = f.read().splitlines()\n",
    "        else:\n",
    "            filenames = [img_path]\n",
    "    else:\n",
    "        filenames = glob.glob(os.path.join(img_path, '**/*'), recursive=True)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # Get the colormap for the depth visualization\n",
    "    cmap = matplotlib.colormaps.get_cmap('Spectral_r')\n",
    "\n",
    "    # Process each image\n",
    "    for k, filename in enumerate(filenames):\n",
    "        print(f'Progress {k+1}/{len(filenames)}: {filename}')\n",
    "\n",
    "        # Read the image\n",
    "        raw_image = cv2.imread(filename)\n",
    "\n",
    "        # Infer depth map from the image\n",
    "        depth = depth_anything.infer_image(raw_image, input_size)\n",
    "\n",
    "        # Normalize depth map\n",
    "        depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "        depth = depth.astype(np.uint8)\n",
    "\n",
    "        # Apply grayscale or color map\n",
    "        if grayscale:\n",
    "            depth = np.repeat(depth[..., np.newaxis], 3, axis=-1)\n",
    "        else:\n",
    "            depth = (cmap(depth)[:, :, :3] * 255)[:, :, ::-1].astype(np.uint8)\n",
    "\n",
    "        # Save the depth map image\n",
    "        depth_map_filename = os.path.join(outdir, os.path.splitext(os.path.basename(filename))[0] + '_depth.png')\n",
    "        cv2.imwrite(depth_map_filename, depth)\n",
    "\n",
    "    print(\"Depth map generation completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will crop the depth maps based on the bounding box created by yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crop Function, txt input , depth map input, cropped depth map output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_labels_from_txt(label_file_path):\n",
    "   \n",
    "    label_data = []\n",
    "    with open(label_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            label = line.strip().split()\n",
    "            label_data.append(label)\n",
    "    return label_data\n",
    "\n",
    "def extract_and_resize(image_path, label_data, output_size=(224, 224)):\n",
    "   \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # List to store resized crops\n",
    "    cropped_resized_images = []\n",
    "\n",
    "    for label in label_data:\n",
    "        class_id, x_center, y_center, box_width, box_height, confidence = map(float, label)\n",
    "\n",
    "        # Convert from relative coordinates to absolute pixel values\n",
    "        x_center_abs = int(x_center * w)\n",
    "        y_center_abs = int(y_center * h)\n",
    "        box_width_abs = int(box_width * w)\n",
    "        box_height_abs = int(box_height * h)\n",
    "\n",
    "        # Calculate the top-left and bottom-right corners of the bounding box\n",
    "        x1 = max(0, x_center_abs - box_width_abs // 2)\n",
    "        y1 = max(0, y_center_abs - box_height_abs // 2)\n",
    "        x2 = min(w, x_center_abs + box_width_abs // 2)\n",
    "        y2 = min(h, y_center_abs + box_height_abs // 2)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Resize the cropped image to the output size\n",
    "        resized_image = cv2.resize(cropped_image, output_size, interpolation=cv2.INTER_AREA)\n",
    "        cropped_resized_images.append(resized_image)\n",
    "\n",
    "    return cropped_resized_images\n",
    "\n",
    "def process_images_and_labels(image_folder, label_folder, output_folder, output_size=(224, 224)):\n",
    "   \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate through all image files in the image folder\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        \n",
    "        # Remove '_depth' from the image file name to match the label file name\n",
    "        base_name = os.path.splitext(image_file)[0].replace('_depth', '')\n",
    "        label_file_path = os.path.join(label_folder, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Check if the label file exists\n",
    "        if os.path.exists(label_file_path):\n",
    "            # Extract label data from the .txt file\n",
    "            label_data = extract_labels_from_txt(label_file_path)\n",
    "            \n",
    "            # Extract and resize the images\n",
    "            resized_images = extract_and_resize(image_path, label_data, output_size)\n",
    "            \n",
    "            # Save the resized images with the modified file name\n",
    "            for idx, img in enumerate(resized_images):\n",
    "                output_file_name = f\"{base_name}depth{idx}.jpg\"\n",
    "                output_file_path = os.path.join(output_folder, output_file_name)\n",
    "                cv2.imwrite(output_file_path, img)\n",
    "                print(f\"Saved: {output_file_path}\")\n",
    "        else:\n",
    "            print(f\"Label file not found for image: {image_file}\")\n",
    "\n",
    "# Example usage:\n",
    "image_folder = 'depth_output'\n",
    "label_folder = labels_path\n",
    "output_folder = 'input_classifier'\n",
    "output_size = (224, 224)  # Example fixed size for the classifier\n",
    "\n",
    "# Process all images and their corresponding labels\n",
    "process_images_and_labels(image_folder, label_folder, output_folder, output_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the yolo classifier to classify if the detection is real or fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo classifier cropped depth map input, new txt output\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load a custom trained model\n",
    "model = YOLO(\"yolocNew.pt\")\n",
    "\n",
    "# Predict on an image\n",
    "# Path to the folder containing images\n",
    "img_folder = \"input_classifier\"\n",
    "\n",
    "# Path to the folder where you want to save the label files\n",
    "labels_folder = labels_path\n",
    "\n",
    "# Ensure labels folder exists\n",
    "os.makedirs(labels_folder, exist_ok=True)\n",
    "\n",
    "# List all image files in the folder (you can modify the extensions as needed)\n",
    "image_files = [f for f in os.listdir(img_folder) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Construct the full path to the image\n",
    "    img_path = os.path.join(img_folder, image_file)\n",
    "\n",
    "    # Predict on the image\n",
    "    results = model(img_path)\n",
    "\n",
    "    # Access probabilities (the 'probs' attribute is a Probs object)\n",
    "    probs = results[0].probs.data  # This is a torch tensor containing class probabilities\n",
    "\n",
    "    # Get the index of the class with the highest probability\n",
    "    predicted_class_index = torch.argmax(probs)\n",
    "\n",
    "    # Map the index to class names\n",
    "    names_dict = results[0].names\n",
    "    predicted_class = names_dict[predicted_class_index.item()] \n",
    "    base_name = os.path.basename(img_path).split('depth')[0]\n",
    "\n",
    "    txt_file_path = os.path.join(labels_folder, base_name + \".txt\")\n",
    "\n",
    "    # Append the predicted class to the text file\n",
    "    with open(txt_file_path, 'a') as file:\n",
    "        file.write(predicted_class + \"\\n\")  # Append predicted class followed by a newline\n",
    "\n",
    "    print(f\"Predicted class '{predicted_class}' appended to {txt_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opencv final image generation, with detection box and label classifying images as fake or real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define class names\n",
    "names = ['AxeHead', 'Grenade', 'Blade', 'Gun', 'fire', 'other', 'smoke']\n",
    "\n",
    "# Paths for images, labels, and output\n",
    "image_folder = \"our_images\"\n",
    "labels_folder = labels_path\n",
    "output_folder = \"labeled_images\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if not image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        continue\n",
    "\n",
    "    # Paths for the image and label files\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    txt_file_path = os.path.join(labels_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
    "\n",
    "    # Skip if the label file doesn't exist\n",
    "    if not os.path.exists(txt_file_path):\n",
    "        print(f\"Warning: No label file found for {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Read label file lines\n",
    "    with open(txt_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Process bounding boxes and their labels\n",
    "    bbox_data = []\n",
    "    for line in lines:\n",
    "        if line.strip().isdigit() or line.strip() in [\"real\", \"fake\"]:\n",
    "            # Store label for the following bounding boxes\n",
    "            label = line.strip()\n",
    "            for bbox in bbox_data:\n",
    "                # Convert bbox relative coordinates to absolute pixel values\n",
    "                index = int(bbox[0])\n",
    "                x_center, y_center, box_width, box_height = map(float, bbox[1:5])\n",
    "                x_center_abs, y_center_abs = int(x_center * w), int(y_center * h)\n",
    "                box_width_abs, box_height_abs = int(box_width * w), int(box_height * h)\n",
    "                \n",
    "                x1, y1 = max(0, x_center_abs - box_width_abs // 2), max(0, y_center_abs - box_height_abs // 2)\n",
    "                x2, y2 = min(w, x_center_abs + box_width_abs // 2), min(h, y_center_abs + box_height_abs // 2)\n",
    "                \n",
    "                # Set color and label text\n",
    "                class_name = names[index]\n",
    "                color = (0, 255, 0) if label == \"real\" else (0, 0, 255)\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "                label_text = f\"{label} {class_name}\"\n",
    "                cv2.putText(image, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Clear bbox data for next label\n",
    "            bbox_data.clear()\n",
    "        else:\n",
    "            # Store bbox line data until label line is found\n",
    "            bbox_data.append(line.strip().split())\n",
    "\n",
    "    # Save the labeled image\n",
    "    output_image_path = os.path.join(output_folder, os.path.splitext(image_file)[0] + \"_labeled.jpg\")\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "    print(f\"Labeled image saved to {output_image_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
